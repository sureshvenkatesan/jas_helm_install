cd /Users/sureshv/myCode/github-sv/jas_helm_install/install_artifactory_from_artifactory_chart/

## Set some environmental variables:
```
export MY_NAMESPACE=jfrog-ns


export MASTER_KEY=$(openssl rand -hex 32)
# Save this master key to reuse it later
echo ${MASTER_KEY}
# or you can hardcode it to
export MASTER_KEY=6dec6691f86d9e3de3cc4645f7a7eb33c3adc31071ec0d6567ad2069295c5397

export JOIN_KEY=$(openssl rand -hex 32)
# Save this join key to reuse it later
echo ${JOIN_KEY}
# or you can hardcode it to
export JOIN_KEY=c64231fe4324121f5de6a5834f35195bba0d857695f80c974c788cfdb4e70f09

export JFROG_URL=http://jpd-artifactory-nginx
```
Note: If the distribution service is in a  different namespace in Kubernetes then for the JFROG_UR , you need to use the fully qualified domain name (FQDN) of the service. Kubernetes automatically creates DNS entries for services within a cluster.

The FQDN for a service in Kubernetes is typically:
<service-name>.<namespace>.svc.cluster.local

Let's say:
The service you want to access from the distribution namespace is named `my-service`.
It is running in the `other-namespace`.
The service exposes HTTP on port `8082`.
The format for the JFROG_URL will be:
`http://my-service.other-namespace.svc.cluster.local:8082`

So verify from a container in distribution namespace if the following works:
```
curl http://my-service.other-namespace.svc.cluster.local:8082/artifactory/api/system/ping
```

Create the secrets:
```
kubectl create secret generic masterkey-secret --from-literal=master-key=${MASTER_KEY} -n $MY_NAMESPACE
kubectl create secret generic joinkey-secret --from-literal=join-key=${JOIN_KEY} -n $MY_NAMESPACE
```

---
## Deploying Distribution via Helm using `jfrog/distribution` chart

1. Switch to the work folder
```
cd /Users/sureshv/myCode/github-sv/jas_helm_install/example_qa_custom_values/mysteps
```

2. Set some more environment variables:
```
export DIST_VERSION=2.25.1
export JFROG_URL="http://35.185.118.92" 
export MY_DIST_HELM_RELEASE=distribution-release
```

---

Check connectivity to Postgres DB using steps from https://github.com/sureshvenkatesan/jas_helm_install/tree/master/install_jfrog_from_platform_chart


```
export DB_SERVER=35.196.8.206
export RT_DATABASE_USER=artifactory
export RT_DATABASE_PASSWORD=password
export ARTIFACTORY_DB=sureshv-helm-ha-db

kubectl run postgres-client --rm --tty -i --restart='Never' --namespace $MY_NAMESPACE \
--image postgres --env="PGPASSWORD=$RT_DATABASE_PASSWORD" \
--command -- psql --host $DB_SERVER -U $RT_DATABASE_USER -d $ARTIFACTORY_DB -c "SELECT version();"
```

3. Pick the Distribution sizing template from https://github.com/jfrog/charts/tree/master/stable/distribution/sizing .
I used [distribution-medium.yaml](https://github.com/jfrog/charts/blob/master/stable/distribution/sizing/distribution-medium.yaml)



4. Verify you have the helm  chart you need:
```
helm repo update
helm search repo jfrog-chart
helm pull jfrog/distribution --version 102.25.1
```

This will download the chart as distribution-102.25.1.tgz

5. First do a Dry run:
```
helm upgrade --install $MY_DIST_HELM_RELEASE \
-f ../distribution/values-main.yaml \
-f ../distribution/distribution-medium.yaml \
--namespace $MY_NAMESPACE \
--set distribution.joinKey="${JOIN_KEY}" \
--set distribution.jfrogUrl="{JFROG_URL}" \
--set global.versions.distribution="${DIST_VERSION}" \
--dry-run \
./distribution-102.25.1.tgz 
```
6. Next run without the --dry-run

---
If for some reason you have uninstall the Distribution release do the following steps from
https://groups.google.com/a/jfrog.com/g/support-followup/c/vSA0hjCiKt4/m/1GNjiaJWAAAJ

One such example is Distribution service is not able to connect to the postgres service bundled in the 
distribution chart and fails with:
```
[c.z.h.p.HikariPool:587        ] [main                ] - Distribution HikariCP - Exception during pool initialization.
org.postgresql.util.PSQLException: FATAL: password authentication failed for user "distribution"
	at org.postgresql.core.v3.ConnectionFactoryImpl.doAuthentication(ConnectionFactoryImpl.java:659)
	at org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:180)
```
The described scenario might happen if Distribution was installed without providing a value to `"postgresql.postgresqlPassword"` .
-  In this case, a password was autogenerated every time you run the "helm upgrade --install" command and it may cause a password mismatch between PostgreSQL DB and Distribution application.

Since it is a new installation (assuming there is no data at all), we might solve this issue by the followings steps:

a) Uninstall the chart - 
helm uninstall <release-name> --namespace <namespace>
```
helm uninstall $MY_DIST_HELM_RELEASE --namespace $MY_NAMESPACE
```
b) Delete PostgreSQL PVC and Redis PVC:
```
kubectl delete pvc data-distribution-<release-name>-0 --namespace <namespace>
kubectl delete pvc redis-data-<release-name>-0 --namespace <namespace>
```
Example:
```
kubectl delete pvc data-distribution-release-postgresql-0 --namespace $MY_NAMESPACE
kubectl delete pvc redis-data-distribution-release-0 --namespace $MY_NAMESPACE
```

c. Next run without the --dry-run
```
helm upgrade --install $MY_DIST_HELM_RELEASE \
-f ../distribution/values-main.yaml \
-f ../distribution/distribution-medium.yaml \
--namespace $MY_NAMESPACE \
--set distribution.joinKey="${JOIN_KEY}" \
--set distribution.jfrogUrl="${JFROG_URL}" \
--set global.versions.distribution="${DIST_VERSION}" \
--set redis.password="distribution" \
--set postgresql.postgresqlPassword="distribution" \
./distribution-102.25.1.tgz 
```


**Note:** Do not use special characters in redis password

When we set Redis and PostgreSQL passwords before the **first** installation, it will give us the ability to run "Helm Upgrade" 
command in the future (version upgrade, values change) without extracting the passwords from the secrets and without generating new passwords. 

More details regarding that you can find https://github.com/jfrog/charts/tree/master/stable/distribution#updating-distribution.

If distribution service is not able to connect to access service of artifactory and fails with:
```
Cluster join: Retry 65: Service registry ping failed, will retry. Error while trying to connect to local router at address 'http://localhost:8046/access': Connect to localhost:8046 [localhost/127.0.0.1] failed: Connection refused
...

Caused by: org.jfrog.bintray.distribution.service.platform.client.exception.ClientBootstrapException: Failed to create Access client
        at org.jfrog.bintray.distribution.service.platform.client.holder.AccessClientHolder.bootstrapClient(AccessClientHolder.java:80)
        at org.jfrog.bintray.distribution.service.platform.client.holder.ClientHolder.getClient(ClientHolder.java:32)
        at org.jfrog.bintray.distribution.service.platform.client.PlatformClientsManagerBase.initializeAccess(PlatformClientsManagerBase.java:277)
        at org.jfrog.bintray.distribution.service.platform.client.PlatformClientsManagerBase.initializePlatformClients(PlatformClientsManagerBase.java:179)
        ... 61 common frames omitted
```

please check if the join key in [values-main.yaml](values-main.yaml) matches the artifactory joinkey in UI.
This should also be the same JOIN_KEY passed in helm upgrade command above.

In my case since I am using `--set distribution.joinKey="${JOIN_KEY}"` I commented off 
`global.joinKeySecretName` in the [values-main.yaml](values-main.yaml) as the mismatch caused the issue.

If not using `--set distribution.joinKey="${JOIN_KEY}"` then make sure it matches the artifactory joinkey in UI.

---
### Troubleshooting steps:
```
kubectl logs distribution-release-postgresql-0 -n jfrog-ns
```
Output:
```
postgresql 09:02:23.88 INFO  ==> 
postgresql 09:02:23.89 INFO  ==> Welcome to the Bitnami postgresql container
postgresql 09:02:23.89 INFO  ==> Subscribe to project updates by watching https://github.com/bitnami/containers
postgresql 09:02:23.89 INFO  ==> Submit issues and feature requests at https://github.com/bitnami/containers/issues
postgresql 09:02:23.89 INFO  ==> 
postgresql 09:02:23.92 INFO  ==> ** Starting PostgreSQL setup **
postgresql 09:02:23.95 INFO  ==> Validating settings in POSTGRESQL_* env vars..
postgresql 09:02:23.96 INFO  ==> Loading custom pre-init scripts...
postgresql 09:02:23.97 INFO  ==> Initializing PostgreSQL database...
mkdir: cannot create directory ‘/bitnami/postgresql/data’: Permission denied
```
I made changes to the postgresql.volumePermissions in the [values-main.yaml](values-main.yaml) for this.

---
```
kubectl exec -it distribution-release-postgresql-0 -n jfrog-ns -- ls -ld /bitnami/postgresql/data
```
Output:
error: Internal error occurred: unable to upgrade connection: container not found ("distribution-release-postgresql")

---
```
kubectl describe secret distribution-release-postgresql -n jfrog-ns
```
Output:
```
Name:         distribution-release-postgresql
Namespace:    jfrog-ns
Labels:       app.kubernetes.io/instance=distribution-release
              app.kubernetes.io/managed-by=Helm
              app.kubernetes.io/name=postgresql
              helm.sh/chart=postgresql-10.3.18
Annotations:  meta.helm.sh/release-name: distribution-release
              meta.helm.sh/release-namespace: jfrog-ns

Type:  Opaque

Data
====
postgresql-password:           10 bytes
postgresql-postgres-password:  10 bytes
```
---
If secrets are missing or incorrect, recreate them:
```
kubectl create secret generic distribution-release-postgresql \
  --from-literal=postgresql-password=<password> \
  --from-literal=postgresql-postgres-password=<admin-password> \
  -n jfrog-ns
```

Verify the secret using:
```
kubectl get secret distribution-release-postgresql -n jfrog-ns -o jsonpath="{.data.postgresql-postgres-password}" | base64 --decode


kubectl get secret distribution-release-postgresql -n jfrog-ns -o jsonpath="{.data.postgresql-password}" | base64 --decode
```
---

Check the postgres DB credentials by connecting to it:
```
psql -h $DISTRIBUTION_RELEASE_POSTGRESQL_SERVICE_HOST -U distribution -d distribution -W

kubectl exec -it distribution-release-postgresql-0 -n jfrog-ns -- psql -U distribution -d distribution


kubectl run alpine --image=alpine --restart=Never --namespace=$MY_NAMESPACE -- sleep 3600
psql -h $DISTRIBUTION_RELEASE_POSTGRESQL_SERVICE_HOST -U distribution -d distribution -W

psql -h $DISTRIBUTION_RELEASE_POSTGRESQL_SERVICE_HOST -U postgres -d distribution -W
```
---


kubectl get secret -n jfrog-ns
```
NAME                                         TYPE                 DATA   AGE
distribution-release-postgresql              Opaque               2      21m
distribution-release-unified-secret          Opaque               2      21m
```

kubectl get secret distribution-release-postgresql -n jfrog-ns -o yaml

kubectl get secret distribution-release-postgresql -n jfrog-ns -o json

kubectl get secret distribution-release-unified-secret -n jfrog-ns -o json

Get the system.yaml and base64 decode it. It was:
```
distribution:
  extraJavaOpts: |
    -XX:InitialRAMPercentage=30 -XX:MaxRAMPercentage=60 -XX:+UseStringDeduplication -XX:MaxMetaspaceSize=300m -Djdk.nio.maxCachedBufferSize=262144 -XX:MaxDirectMemorySize=256m
router:
  serviceRegistry:
    insecure: false
shared:
  database:
    driver: org.postgresql.Driver
    type: postgresql
    url: postgresql://distribution-release-postgresql:5432/distribution
    username: distribution
  jfrogUrl: http://35.185.118.92
  logging:
    consoleLog:
      enabled: false
```
---

kubectl exec -it distribution-release-0 -- bash
Output:
```
Defaulted container "distribution" out of: distribution, router, observability, redis, copy-system-configurations (init), wait-for-db (init)
error: Internal error occurred: unable to upgrade connection: container not found ("distribution")
```

At one point I found that the `jfrogUrl` in the sytem.yaml was not set properly using:
```
cd /opt/jfrog/distribution/var/log
cd /opt/jfrog/distribution/var/data/distribution

bash-5.1$ cat /opt/jfrog/distribution/var/etc/system.yaml
distribution:
    extraJavaOpts: |
        -XX:InitialRAMPercentage=30 -XX:MaxRAMPercentage=60 -XX:+UseStringDeduplication -XX:MaxMetaspaceSize=300m -Djdk.nio.maxCachedBufferSize=262144 -XX:MaxDirectMemorySize=256m
router:
    serviceRegistry:
        insecure: false
shared:
    database:
        driver: org.postgresql.Driver
        type: postgresql
        url: postgresql://distribution-release-postgresql:5432/distribution
        username: distribution
    jfrogUrl: '[JFROG_URL]'
    logging:
        consoleLog:
            enabled: false
```
---


